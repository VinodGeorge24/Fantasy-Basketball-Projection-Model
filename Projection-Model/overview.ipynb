{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the lists steps of model: \n",
    "\n",
    "1. normalize player data across seasons\n",
    "2. find 10 most similar player seasons historically\n",
    "3. rank and weight each of those 10 players season stats (depending on how similar they are statiscally)\n",
    "4. look at 10 players following seasons stats \n",
    "5. use weighted averages to predict current players next season\n",
    "6. rinse and repeat for every player in 2017-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why use normalized data vs original data (step 1)?\n",
    "\n",
    "league avg change over time, we want to compare their stats regardless of change\n",
    "\n",
    "similarity outside of those league based differences (i.e. 3 point shooting diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cumulative number used for our comparison: percent error\n",
    "\n",
    "to measure distance between players of their groups of stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more weight = more similar\n",
    "\n",
    "________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Useful ChatGPT Machine Learning Examples, specifically talking ab the k-NN model: \n",
    "\n",
    "Loading the Iris dataset: The Iris dataset is loaded using the load_iris function from scikit-learn. This dataset is often used for testing and demonstration purposes.\n",
    "\n",
    "Splitting the data: The data is split into training and testing sets using the train_test_split function. Here, 20% of the data is reserved for testing.\n",
    "\n",
    "Standardizing the features: The features are standardized using the StandardScaler to have a mean of 0 and a standard deviation of 1. This step helps improve the performance of the k-NN algorithm.\n",
    "\n",
    "Creating and training the k-NN model: The KNeighborsClassifier is instantiated with n_neighbors=3, meaning it will consider the 3 nearest neighbors. The model is then trained using the fit method.\n",
    "\n",
    "Making predictions: The trained model is used to make predictions on the test set.\n",
    "\n",
    "Evaluating the model: The accuracy of the model is calculated using the accuracy_score function, which compares the predicted labels with the true labels.\n",
    "\n",
    "\n",
    "In machine learning, splitting the dataset into training and testing sets is a crucial step. This split allows you to train your model on one portion of the data (the training set) and evaluate its performance on another portion (the testing set) that it hasn't seen before. This helps to ensure that the model generalizes well to new, unseen data.\n",
    "\n",
    "The train_test_split function from the scikit-learn library is used to perform this split. It is not a preset function within load_iris, but rather a utility function that you can use after loading the dataset.\n",
    "\n",
    "Explanation of Data Splitting\n",
    "Training Set: This is the portion of the data that the model will learn from. The model uses this data to understand patterns and relationships.\n",
    "\n",
    "Testing Set: This is the portion of the data used to evaluate the model's performance. It helps to check how well the model performs on data it hasn't seen during training."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
